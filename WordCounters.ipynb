{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count words by part of speech\n",
    "MODULES:\n",
    "SpaCy version 2.0.18; es_core_news_md 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataset(csv_file_name):\n",
    "    data = pd.read_csv(csv_file_name, sep=',')\n",
    "    text = data.text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#INSERT THE .CSV FILE NAME BETWEEN THE PARENTHESIS, WITH QUOTES\n",
    "text = fetch_dataset()\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#THIS IS SET UP FOR SPANISH LANGUAGE TEXT\n",
    "#REQUIRES TIME FOR PROCESSING\n",
    "nlp = spacy.load('es_core_news_md')\n",
    "mydict = {}\n",
    "pos = []\n",
    "tokens = []\n",
    "occurr = []\n",
    "\n",
    "for sent in text:\n",
    "    doc = nlp(sent)\n",
    "    for token in doc:   \n",
    "        mydict[token] = token.pos_\n",
    "print(\"Number of tokens:\", len(mydict))\n",
    "\n",
    "for key,val in mydict.items():\n",
    "    tokens.append(str(key))\n",
    "    pos.append(val)\n",
    "    occurr.append(int(1))\n",
    "print(\"Three columns - python lists - preprocessed for pandas dataframe: 'tokens', 'pos', and 'occurr'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's make a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'TOKEN' : tokens, \n",
    "                  'POS' : pos,\n",
    "                 'occurr' : occurr})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_count = df.groupby('POS')['TOKEN'].nunique()\n",
    "print('PART OF SPEECH BREAKDOWN')\n",
    "pos_count.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = df.groupby('POS')\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_hist(part_of_speech):\n",
    "    grup = g.get_group(part_of_speech)\n",
    "    grup_sum = grup.groupby('TOKEN')['occurr'].sum()\n",
    "    return grup_sum.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter the part of speech abbreviation* you want to count\n",
    "*see \"PART OF SPEECH BREAKDOWN\" above for list of abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ENTER PART OF SPEECH ABBREVIATION \n",
    "get_word_hist('NOUN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
